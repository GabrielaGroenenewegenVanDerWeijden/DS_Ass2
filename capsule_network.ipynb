{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Capsule Network model on Pneumonia dataset\n",
    "\n",
    "An adaptation from the MNIST baseline model created in the other file named such"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialisation and setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "cutoff = 128  # 0 == use all\n",
    "\n",
    "epochs = 2\n",
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "capsule_iterations = 3\n",
    "\n",
    "num_filters = 256\n",
    "num_base_mappings = 32\n",
    "dim_base_capsules = num_filters // num_base_mappings\n",
    "\n",
    "num_super_capsules = 10\n",
    "dim_super_capsules = 16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['PNEUMONIA', 'NORMAL']\n",
    "# img_size = 150\n",
    "img_size = 28\n",
    "\n",
    "def get_training_data(data_dir):\n",
    "    data = []\n",
    "    for label in labels:\n",
    "        path = os.path.join(data_dir, label)\n",
    "        class_num = labels.index(label)\n",
    "        for img in os.listdir(path):\n",
    "            try:\n",
    "                img_path = os.path.join(path, img)\n",
    "                img_arr = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "                if img_arr is None:\n",
    "                    continue\n",
    "                resized_arr = cv2.resize(img_arr, (img_size, img_size))\n",
    "                data.append([resized_arr, class_num])\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing {img_path}: {e}\")\n",
    "    return np.array(data, dtype=object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_set = get_training_data('Data/chest_xray/chest_xray/train')\n",
    "# test_set = get_training_data('Data/chest_xray/chest_xray/test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = []\n",
    "y_train = []\n",
    "for feature, label in train_set:\n",
    "    X_train.append(feature)\n",
    "    y_train.append(label)\n",
    "\n",
    "X_test = []\n",
    "y_test = []\n",
    "for feature, label in test_set:\n",
    "    X_test.append(feature)\n",
    "    y_test.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (X_train, y_train), (X_test , y_test) = tf.keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Normalisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([5216, 28, 28, 1]), TensorShape([624, 28, 28, 1]))"
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = np.array(X_train) / 255.0\n",
    "X_train = tf.cast(X_train, dtype=tf.float32)\n",
    "X_train = tf.expand_dims(X_train, axis=-1)\n",
    "\n",
    "X_test = np.array(X_test) / 255.0\n",
    "X_test = tf.cast(X_test, dtype=tf.float32)\n",
    "X_test = tf.expand_dims(X_test, axis=-1)\n",
    "\n",
    "\n",
    "y_train = np.array(y_train)\n",
    "y_test = np.array(y_test)\n",
    "\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cutoff data used for quicker development"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use a smaller set for development and testing\n",
    "if cutoff > 0:\n",
    "    try:\n",
    "        X_train, y_train = X_train[:cutoff], y_train[:cutoff]\n",
    "    except Exception as e:\n",
    "        pass\n",
    "    try:\n",
    "        X_test, y_test = X_test[:cutoff], y_test[:cutoff]\n",
    "    except Exception as e:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Process and augment data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_trainset = X_train.shape[0]\n",
    "n_testset = X_test.shape[0]\n",
    "\n",
    "dim_imgs = X_train.shape[1]\n",
    "\n",
    "# dataset = tf.data.Dataset.from_tensor_slices((X_train, y_train))\n",
    "# dataset = dataset.shuffle(buffer_size=len(dataset), reshuffle_each_iteration=True)\n",
    "# dataset = dataset.batch(batch_size=batch_size)\n",
    "\n",
    "# testset = tf.data.Dataset.from_tensor_slices((X_test, y_test))\n",
    "# testset = testset.batch(batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "DataGenerator = tf.keras.preprocessing.image.ImageDataGenerator\n",
    "datagen = DataGenerator(\n",
    "        featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "        samplewise_center=False,  # set each sample mean to 0\n",
    "        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "        samplewise_std_normalization=False,  # divide each input by its std\n",
    "        zca_whitening=False,  # apply ZCA whitening\n",
    "        rotation_range = 30,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "        zoom_range = 0.2, # Randomly zoom image\n",
    "        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
    "        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
    "        horizontal_flip = True,  # randomly flip images\n",
    "        vertical_flip=False  # randomly flip images\n",
    ")\n",
    "\n",
    "datagen.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "augmented_dataset = datagen.flow(X_train, y_train)\n",
    "\n",
    "X_train = augmented_dataset.x\n",
    "y_train = augmented_dataset.y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = tf.data.Dataset.from_tensor_slices((X_train, y_train))\n",
    "dataset = dataset.shuffle(buffer_size=len(dataset), reshuffle_each_iteration=True)\n",
    "dataset = dataset.batch(batch_size=batch_size)\n",
    "\n",
    "testset = tf.data.Dataset.from_tensor_slices((X_test, y_test))\n",
    "testset = testset.batch(batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_BatchDataset element_spec=(TensorSpec(shape=(None, 28, 28, 1), dtype=tf.float32, name=None), TensorSpec(shape=(None,), dtype=tf.int64, name=None))>"
      ]
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Util functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_layer_output_imgsize(input_size: int, kernel_size: int = 9, strides: int = 1):\n",
    "    return (input_size - kernel_size) // strides\n",
    "\n",
    "def get_img_dims(img) -> int:\n",
    "    return img.shape[1], img.shape[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "def safe_normalise(vector, axis=1, epsilon=1e-7, keepdims=True):\n",
    "    norm_squared = tf.reduce_sum(tf.square(vector), axis, keepdims)\n",
    "    return tf.sqrt(norm_squared + epsilon)  # epsilon added to prevent division by 0\n",
    "\n",
    "def safe_squash(vector, axis=1, epsilon=1e-7):\n",
    "    norm_squared = tf.reduce_sum(\n",
    "        tf.square(vector), \n",
    "        axis=axis, \n",
    "        keepdims=True\n",
    "    )\n",
    "    scalar_factor = norm_squared / (1 + norm_squared)\n",
    "    \n",
    "    safe_normalise = tf.sqrt(norm_squared + epsilon)  # epsilon added to prevent division by 0\n",
    "    unit_vector = vector / safe_normalise\n",
    "    return scalar_factor * unit_vector\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_function(\n",
    "    vector, \n",
    "    reconstructed_image, \n",
    "    y, \n",
    "    y_image,\n",
    "    epsilon=1e-7,\n",
    "    m_plus=0.9,\n",
    "    m_minus=0.1,\n",
    "    lambda_=0.5,\n",
    "    alpha=0.0005,\n",
    "):\n",
    "    img_dim_w, img_dim_h = img_size, img_size\n",
    "    img_resolution = img_dim_w * img_dim_h\n",
    "\n",
    "    safe_normal = safe_normalise(vector, axis=-1, keepdims=True, epsilon=epsilon)\n",
    "    prediction = tf.reshape(safe_normal, [-1, num_super_capsules])\n",
    "\n",
    "    left_margin = tf.square(tf.maximum(0.0, m_plus - prediction))\n",
    "    right_margin = tf.square(tf.maximum(0.0, prediction - m_minus))\n",
    "\n",
    "    margin_loss = tf.add(y * left_margin, lambda_ * (1.0 - y) * right_margin)\n",
    "    margin_loss = tf.reduce_mean(tf.reduce_sum(margin_loss, axis=-1))\n",
    "\n",
    "    y_image_flat = tf.reshape(y_image, [-1, img_resolution])\n",
    "    # print(f\"{y_image_flat.shape= }\")\n",
    "    reconstruction_loss = tf.reduce_mean(tf.square(y_image_flat - reconstructed_image))\n",
    "\n",
    "    loss = tf.add(margin_loss, alpha * reconstruction_loss)\n",
    "\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the Capsule Network class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class CapsuleNetwork(tf.keras.Model):\n",
    "#     def __init__(\n",
    "#         self, \n",
    "#         num_filters, \n",
    "#         num_base_mappings, dim_base_capsules, \n",
    "#         num_super_capsules, dim_super_capsules, \n",
    "#         iterations: int = 3,\n",
    "#         kernel_size: int = 9):\n",
    "#         super().__init__()\n",
    "#         self.num_filters = num_filters\n",
    "#         self.num_base_mappings = num_base_mappings\n",
    "#         self.dim_base_capsules = dim_base_capsules\n",
    "#         self.num_super_capsules = num_super_capsules\n",
    "#         self.dim_super_capsules = dim_super_capsules\n",
    "\n",
    "#         self.iterations = iterations\n",
    "#         self.kernel_size = kernel_size\n",
    "\n",
    "#         with tf.name_scope(\"Variables\") as scope:\n",
    "#             kernel = [self.kernel_size, self.kernel_size]\n",
    "            \n",
    "#             self.convolution = tf.keras.layers.Conv2D(self.num_filters, kernel, strides=[1,1], name='ConvolutionLayer', activation='relu')\n",
    "#             dim_layer1_output = get_layer_output_imgsize(dim_imgs, self.kernel_size, strides=1)\n",
    "\n",
    "#             self.base_capsule = tf.keras.layers.Conv2D(self.num_base_mappings * self.dim_base_capsules, kernel, strides=[2,2], name=\"BaseCapsule\")\n",
    "#             dim_layer2_output = get_layer_output_imgsize(dim_layer1_output, self.kernel_size, strides=2)\n",
    "            \n",
    "#             self.num_base_capsules = self.num_base_mappings * dim_layer2_output ** 2\n",
    "#             # self.num_base_capsules = self.num_base_mappings * 6 ** 2\n",
    "#             self.w = tf.Variable(\n",
    "#                 tf.random_normal_initializer()(shape=[\n",
    "#                     1, \n",
    "#                     self.num_base_capsules, self.num_super_capsules, \n",
    "#                     self.dim_super_capsules, self.dim_base_capsules\n",
    "#                     ]), \n",
    "#                 dtype=tf.float32, \n",
    "#                 name=\"PoseEstimation\", \n",
    "#                 trainable=True)\n",
    "            \n",
    "#             self.dense_1 = tf.keras.layers.Dense(units = 512, activation='relu')\n",
    "#             self.dense_2 = tf.keras.layers.Dense(units = 1024, activation='relu')\n",
    "#             self.dense_3 = tf.keras.layers.Dense(units = 784, activation='sigmoid', dtype='float32')\n",
    "\n",
    "#     def build(self, input_shape):\n",
    "#         pass\n",
    "\n",
    "#     def squash(self, vector, epsilon=1e-7):\n",
    "#         with tf.name_scope(\"SafeSquashFunction\") as scope:\n",
    "#             norm_squared = tf.reduce_sum(\n",
    "#                 tf.square(vector), \n",
    "#                 axis=-1, \n",
    "#                 keepdims=True\n",
    "#             )\n",
    "#             scalar_factor = norm_squared / (1 + norm_squared)\n",
    "            \n",
    "#             safety_normalise = tf.sqrt(norm_squared + epsilon)\n",
    "#             unit_vector = vector / safety_normalise\n",
    "#             return scalar_factor * unit_vector\n",
    "\n",
    "#     @tf.function\n",
    "#     def call(self, inputs):\n",
    "#         input_x, y = inputs\n",
    "#         # input_x.shape: (None, 28, 28, 1)\n",
    "#         # y.shape: (None, 10)\n",
    "\n",
    "#         x = self.convolution(input_x) # x.shape: (None, 20, 20, 256)\n",
    "#         x = self.base_capsule(x) # x.shape: (None, 6, 6, 256)\n",
    "\n",
    "#         with tf.name_scope(\"CapsuleFormation\") as scope:\n",
    "#             u = tf.reshape(x, (-1, self.num_base_capsules, self.dim_base_capsules)) # u.shape: (None, 1152, 8)\n",
    "#             u = tf.expand_dims(u, axis=-2) # u.shape: (None, 1152, 1, 8)\n",
    "#             u = tf.expand_dims(u, axis=-1) # u.shape: (None, 1152, 1, 8, 1)\n",
    "#             u_hat = tf.matmul(self.w, u) # u_hat.shape: (None, 1152, 10, 16, 1)\n",
    "#             u_hat = tf.squeeze(u_hat, [4]) # u_hat.shape: (None, 1152, 10, 16)\n",
    "\n",
    "\n",
    "#         with tf.name_scope(\"DynamicRouting\") as scope:\n",
    "#             b = tf.zeros((input_x.shape[0], self.num_base_capsules, self.num_super_capsules, 1)) # b.shape: (None, 1152, 10, 1)\n",
    "#             for i in range(self.iterations): # self.iterations = 3\n",
    "#                 c = tf.nn.softmax(b, axis=-2) # c.shape: (None, 1152, 10, 1)\n",
    "#                 s = tf.reduce_sum(tf.multiply(c, u_hat), axis=1, keepdims=True) # s.shape: (None, 1, 10, 16)\n",
    "#                 v = self.squash(s) # v.shape: (None, 1, 10, 16)\n",
    "#                 agreement = tf.squeeze(tf.matmul(tf.expand_dims(u_hat, axis=-1), tf.expand_dims(v, axis=-1), transpose_a=True), [4]) # agreement.shape: (None, 1152, 10, 1)\n",
    "#                 # Before matmul following intermediate shapes are present, they are not assigned to a variable but just for understanding the code.\n",
    "#                 # u_hat.shape (Intermediate shape) : (None, 1152, 10, 16, 1)\n",
    "#                 # v.shape (Intermediate shape): (None, 1, 10, 16, 1)\n",
    "#                 # Since the first parameter of matmul is to be transposed its shape becomes:(None, 1152, 10, 1, 16)\n",
    "#                 # Now matmul is performed in the last two dimensions, and others are broadcasted\n",
    "#                 # Before squeezing we have an intermediate shape of (None, 1152, 10, 1, 1)\n",
    "#                 b += agreement\n",
    "\n",
    "#         with tf.name_scope(\"Masking\") as scope:\n",
    "#             y = tf.expand_dims(y, axis=-1) # y.shape: (None, 10, 1)\n",
    "#             y = tf.expand_dims(y, axis=1) # y.shape: (None, 1, 10, 1)\n",
    "#             mask = tf.cast(y, dtype=tf.float32) # mask.shape: (None, 1, 10, 1)\n",
    "#             v_masked = tf.multiply(mask, v) # v_masked.shape: (None, 1, 10, 16)\n",
    "\n",
    "#         with tf.name_scope(\"Reconstruction\") as scope:\n",
    "#             v_ = tf.reshape(v_masked, [-1, self.num_super_capsules * self.dim_super_capsules]) # v_.shape: (None, 160)\n",
    "#             reconstructed_image = self.dense_1(v_) # reconstructed_image.shape: (None, 512)\n",
    "#             reconstructed_image = self.dense_2(reconstructed_image) # reconstructed_image.shape: (None, 1024)\n",
    "#             reconstructed_image = self.dense_3(reconstructed_image) # reconstructed_image.shape: (None, 784)\n",
    "\n",
    "#         return v, reconstructed_image\n",
    "\n",
    "#     @tf.function\n",
    "#     def predict_capsule_output(self, inputs):\n",
    "#         x = self.convolution(inputs) # x.shape: (None, 20, 20, 256)\n",
    "#         x = self.base_capsule(x) # x.shape: (None, 6, 6, 256)\n",
    "\n",
    "#         with tf.name_scope(\"CapsuleFormation\") as scope:\n",
    "#             u = tf.reshape(x, (-1, self.num_base_capsules, self.dim_base_capsules)) # u.shape: (None, 1152, 8)\n",
    "#             u = tf.expand_dims(u, axis=-2) # u.shape: (None, 1152, 1, 8)\n",
    "#             u = tf.expand_dims(u, axis=-1) # u.shape: (None, 1152, 1, 8, 1)\n",
    "#             u_hat = tf.matmul(self.w, u) # u_hat.shape: (None, 1152, 10, 16, 1)\n",
    "#             u_hat = tf.squeeze(u_hat, [4]) # u_hat.shape: (None, 1152, 10, 16)\n",
    "\n",
    "\n",
    "#         with tf.name_scope(\"DynamicRouting\") as scope:\n",
    "#             b = tf.zeros((inputs.shape[0], self.num_base_capsules, self.num_super_capsules, 1)) # b.shape: (None, 1152, 10, 1)\n",
    "#             for i in range(self.iterations): # self.iterations = 3\n",
    "#                 c = tf.nn.softmax(b, axis=-2) # c.shape: (None, 1152, 10, 1)\n",
    "#                 s = tf.reduce_sum(tf.multiply(c, u_hat), axis=1, keepdims=True) # s.shape: (None, 1, 10, 16)\n",
    "#                 v = self.squash(s) # v.shape: (None, 1, 10, 16)\n",
    "#                 agreement = tf.squeeze(tf.matmul(tf.expand_dims(u_hat, axis=-1), tf.expand_dims(v, axis=-1), transpose_a=True), [4]) # agreement.shape: (None, 1152, 10, 1)\n",
    "#                 # Before matmul following intermediate shapes are present, they are not assigned to a variable but just for understanding the code.\n",
    "#                 # u_hat.shape (Intermediate shape) : (None, 1152, 10, 16, 1)\n",
    "#                 # v.shape (Intermediate shape): (None, 1, 10, 16, 1)\n",
    "#                 # Since the first parameter of matmul is to be transposed its shape becomes:(None, 1152, 10, 1, 16)\n",
    "#                 # Now matmul is performed in the last two dimensions, and others are broadcasted\n",
    "#                 # Before squeezing we have an intermediate shape of (None, 1152, 10, 1, 1)\n",
    "#                 b += agreement\n",
    "#         return v\n",
    "\n",
    "#     @tf.function\n",
    "#     def regenerate_image(self, inputs):\n",
    "#         with tf.name_scope(\"Reconstruction\") as scope:\n",
    "#             v_ = tf.reshape(inputs, [-1, self.num_super_capsules * self.dim_super_capsules]) # v_.shape: (None, 160)\n",
    "#             reconstructed_image = self.dense_1(v_) # reconstructed_image.shape: (None, 512)\n",
    "#             reconstructed_image = self.dense_2(reconstructed_image) # reconstructed_image.shape: (None, 1024)\n",
    "#             reconstructed_image = self.dense_3(reconstructed_image) # reconstructed_image.shape: (None, 784)\n",
    "#         return reconstructed_image\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CapsuleNetwork(tf.keras.Model):\n",
    "    def __init__(\n",
    "        self, \n",
    "        num_filters, \n",
    "        num_base_mappings, dim_base_capsules, \n",
    "        num_super_capsules, dim_super_capsules, \n",
    "        iterations: int = 3,\n",
    "        kernel_size: int = 9):\n",
    "        super().__init__()\n",
    "        self.num_filters = num_filters  # 256\n",
    "        self.num_base_mappings = num_base_mappings  # 32\n",
    "        self.dim_base_capsules = dim_base_capsules  # 8\n",
    "        self.num_super_capsules = num_super_capsules  # 10\n",
    "        self.dim_super_capsules = dim_super_capsules  # 16\n",
    "        self.num_base_capsules = self.num_base_mappings * 6 ** 2  # 1152\n",
    "\n",
    "        self.iterations = iterations\n",
    "        self.kernel_size = kernel_size\n",
    "\n",
    "        with tf.name_scope(\"Variables\") as scope:\n",
    "            kernel = [self.kernel_size, self.kernel_size]\n",
    "            \n",
    "            self.convolution = tf.keras.layers.Conv2D(self.num_filters, kernel, strides=[1,1], name='ConvolutionLayer', activation='relu')\n",
    "            self.base_capsule = tf.keras.layers.Conv2D(self.num_base_mappings * self.dim_base_capsules, kernel, strides=[2,2], name=\"BaseCapsule\")\n",
    "            self.w = tf.Variable(\n",
    "                tf.random_normal_initializer()(shape=[\n",
    "                    1, \n",
    "                    self.num_base_capsules, self.num_super_capsules, \n",
    "                    self.dim_super_capsules, self.dim_base_capsules\n",
    "                    ]), \n",
    "                dtype=tf.float32, \n",
    "                name=\"PoseEstimation\", \n",
    "                trainable=True)\n",
    "            \n",
    "            self.dense_1 = tf.keras.layers.Dense(units = 512, activation='relu')\n",
    "            self.dense_2 = tf.keras.layers.Dense(units = 1024, activation='relu')\n",
    "            self.dense_3 = tf.keras.layers.Dense(units = 784, activation='sigmoid', dtype='float32')\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        pass\n",
    "\n",
    "    def squash(self, vector, epsilon=1e-7):\n",
    "        with tf.name_scope(\"SafeSquashFunction\") as scope:\n",
    "            norm_squared = tf.reduce_sum(\n",
    "                tf.square(vector), \n",
    "                axis=-1, \n",
    "                keepdims=True\n",
    "            )\n",
    "            scalar_factor = norm_squared / (1 + norm_squared)\n",
    "            \n",
    "            safety_normalise = tf.sqrt(norm_squared + epsilon)\n",
    "            unit_vector = vector / safety_normalise\n",
    "            return scalar_factor * unit_vector\n",
    "\n",
    "    @tf.function\n",
    "    def call(self, inputs):\n",
    "        input_x, y = inputs\n",
    "        # input_x.shape: (None, 28, 28, 1)\n",
    "        # y.shape: (None, 10)\n",
    "\n",
    "        x = self.convolution(input_x) # x.shape: (None, 20, 20, 256)\n",
    "        x = self.base_capsule(x) # x.shape: (None, 6, 6, 256)\n",
    "        # print(f\"{x.shape= }\")\n",
    "\n",
    "        with tf.name_scope(\"CapsuleFormation\") as scope:\n",
    "            u = tf.reshape(x, (-1, self.num_base_mappings * x.shape[1] * x.shape[2], self.dim_base_capsules)) # u.shape: (None, 1152, 8)\n",
    "            u = tf.expand_dims(u, axis=-2) # u.shape: (None, 1152, 1, 8)\n",
    "            u = tf.expand_dims(u, axis=-1) # u.shape: (None, 1152, 1, 8, 1)\n",
    "            u_hat = tf.matmul(self.w, u) # u_hat.shape: (None, 1152, 10, 16, 1)\n",
    "            u_hat = tf.squeeze(u_hat, [4]) # u_hat.shape: (None, 1152, 10, 16)\n",
    "\n",
    "\n",
    "        with tf.name_scope(\"DynamicRouting\") as scope:\n",
    "            b = tf.zeros((input_x.shape[0], 1152, self.num_super_capsules, 1)) # b.shape: (None, 1152, 10, 1)\n",
    "            for i in range(self.iterations): # self.iterations = 3\n",
    "                c = tf.nn.softmax(b, axis=-2) # c.shape: (None, 1152, 10, 1)\n",
    "                s = tf.reduce_sum(tf.multiply(c, u_hat), axis=1, keepdims=True) # s.shape: (None, 1, 10, 16)\n",
    "                v = self.squash(s) # v.shape: (None, 1, 10, 16)\n",
    "                agreement = tf.squeeze(tf.matmul(tf.expand_dims(u_hat, axis=-1), tf.expand_dims(v, axis=-1), transpose_a=True), [4]) # agreement.shape: (None, 1152, 10, 1)\n",
    "                # Before matmul following intermediate shapes are present, they are not assigned to a variable but just for understanding the code.\n",
    "                # u_hat.shape (Intermediate shape) : (None, 1152, 10, 16, 1)\n",
    "                # v.shape (Intermediate shape): (None, 1, 10, 16, 1)\n",
    "                # Since the first parameter of matmul is to be transposed its shape becomes:(None, 1152, 10, 1, 16)\n",
    "                # Now matmul is performed in the last two dimensions, and others are broadcasted\n",
    "                # Before squeezing we have an intermediate shape of (None, 1152, 10, 1, 1)\n",
    "                b += agreement\n",
    "\n",
    "        with tf.name_scope(\"Masking\") as scope:\n",
    "            y = tf.expand_dims(y, axis=-1) # y.shape: (None, 10, 1)\n",
    "            y = tf.expand_dims(y, axis=1) # y.shape: (None, 1, 10, 1)\n",
    "            mask = tf.cast(y, dtype=tf.float32) # mask.shape: (None, 1, 10, 1)\n",
    "            v_masked = tf.multiply(mask, v) # v_masked.shape: (None, 1, 10, 16)\n",
    "\n",
    "        with tf.name_scope(\"Reconstruction\") as scope:\n",
    "            v_ = tf.reshape(v_masked, [-1, self.num_super_capsules * self.dim_super_capsules]) # v_.shape: (None, 160)\n",
    "            reconstructed_image = self.dense_1(v_) # reconstructed_image.shape: (None, 512)\n",
    "            reconstructed_image = self.dense_2(reconstructed_image) # reconstructed_image.shape: (None, 1024)\n",
    "            reconstructed_image = self.dense_3(reconstructed_image) # reconstructed_image.shape: (None, 784)\n",
    "\n",
    "        return v, reconstructed_image\n",
    "\n",
    "    @tf.function\n",
    "    def predict_capsule_output(self, inputs):\n",
    "        x = self.convolution(inputs) # x.shape: (None, 20, 20, 256)\n",
    "        x = self.base_capsule(x) # x.shape: (None, 6, 6, 256)\n",
    "\n",
    "        with tf.name_scope(\"CapsuleFormation\") as scope:\n",
    "            u = tf.reshape(x, (-1, self.num_base_capsules, self.dim_base_capsules)) # u.shape: (None, 1152, 8)\n",
    "            u = tf.expand_dims(u, axis=-2) # u.shape: (None, 1152, 1, 8)\n",
    "            u = tf.expand_dims(u, axis=-1) # u.shape: (None, 1152, 1, 8, 1)\n",
    "            u_hat = tf.matmul(self.w, u) # u_hat.shape: (None, 1152, 10, 16, 1)\n",
    "            u_hat = tf.squeeze(u_hat, [4]) # u_hat.shape: (None, 1152, 10, 16)\n",
    "\n",
    "\n",
    "        with tf.name_scope(\"DynamicRouting\") as scope:\n",
    "            b = tf.zeros((inputs.shape[0], 1152, self.num_super_capsules, 1)) # b.shape: (None, 1152, 10, 1)\n",
    "            for i in range(self.iterations): # self.iterations = 3\n",
    "                c = tf.nn.softmax(b, axis=-2) # c.shape: (None, 1152, 10, 1)\n",
    "                s = tf.reduce_sum(tf.multiply(c, u_hat), axis=1, keepdims=True) # s.shape: (None, 1, 10, 16)\n",
    "                v = self.squash(s) # v.shape: (None, 1, 10, 16)\n",
    "                agreement = tf.squeeze(tf.matmul(tf.expand_dims(u_hat, axis=-1), tf.expand_dims(v, axis=-1), transpose_a=True), [4]) # agreement.shape: (None, 1152, 10, 1)\n",
    "                # Before matmul following intermediate shapes are present, they are not assigned to a variable but just for understanding the code.\n",
    "                # u_hat.shape (Intermediate shape) : (None, 1152, 10, 16, 1)\n",
    "                # v.shape (Intermediate shape): (None, 1, 10, 16, 1)\n",
    "                # Since the first parameter of matmul is to be transposed its shape becomes:(None, 1152, 10, 1, 16)\n",
    "                # Now matmul is performed in the last two dimensions, and others are broadcasted\n",
    "                # Before squeezing we have an intermediate shape of (None, 1152, 10, 1, 1)\n",
    "                b += agreement\n",
    "        return v\n",
    "\n",
    "    @tf.function\n",
    "    def regenerate_image(self, inputs):\n",
    "        with tf.name_scope(\"Reconstruction\") as scope:\n",
    "            v_ = tf.reshape(inputs, [-1, self.num_super_capsules * self.dim_super_capsules]) # v_.shape: (None, 160)\n",
    "            reconstructed_image = self.dense_1(v_) # reconstructed_image.shape: (None, 512)\n",
    "            reconstructed_image = self.dense_2(reconstructed_image) # reconstructed_image.shape: (None, 1024)\n",
    "            reconstructed_image = self.dense_3(reconstructed_image) # reconstructed_image.shape: (None, 784)\n",
    "        return reconstructed_image\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instantiate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No `profiler_outdir` passed to trace_on(). Profiler won't be enabled.\n"
     ]
    }
   ],
   "source": [
    "tf.summary.trace_on(graph=True, profiler=True)\n",
    "model = CapsuleNetwork(\n",
    "    num_filters=num_filters,\n",
    "    num_base_mappings=num_base_mappings,\n",
    "    dim_base_capsules=dim_base_capsules,\n",
    "    num_super_capsules=num_super_capsules,\n",
    "    dim_super_capsules=dim_super_capsules,\n",
    "    iterations=capsule_iterations\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "Optimiser = tf.keras.optimizers.Adam()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Error while stopping profiler: Cannot export profiling results. No profiler is running.\n"
     ]
    }
   ],
   "source": [
    "def train(X, y) -> float:\n",
    "    y_one_hot = tf.one_hot(y, depth=num_super_capsules)\n",
    "    with tf.GradientTape() as tape:\n",
    "        vector, reconstructed_image = model([X, y_one_hot])\n",
    "        loss = loss_function(vector, reconstructed_image, y_one_hot, X)\n",
    "    grad = tape.gradient(loss, model.trainable_variables)\n",
    "    Optimiser.apply_gradients(zip(grad, model.trainable_variables))\n",
    "    return loss\n",
    "\n",
    "_ = train(X_train[:32], y_train[:32])\n",
    "\n",
    "tf.summary.trace_off()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, x):\n",
    "    pred = model.predict_capsule_output(x)\n",
    "    pred_normed = safe_normalise(pred)\n",
    "    pred_normed = tf.squeeze(pred_normed, [1])\n",
    "    return np.argmax(pred_normed, axis=1)[:,0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/2:   0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 15 calls to <function CapsuleNetwork.call at 0x0000016912ED4720> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/2: 100%|██████████| 2/2 [00:14<00:00,  7.42s/it, Loss :1.458375 Accuracy :1.0]          \n",
      "Epoch 2/2: 100%|██████████| 2/2 [00:13<00:00,  7.00s/it, Loss :0.45785064 Accuracy :1.0]          \n"
     ]
    }
   ],
   "source": [
    "checkpoint = tf.train.Checkpoint(model=model)\n",
    "losses = []\n",
    "accuracy = []\n",
    "for i in range(1, epochs+1, 1):\n",
    "\n",
    "    loss = 0\n",
    "    with tqdm(total=len(dataset)) as pbar:\n",
    "\n",
    "        description = \"Epoch \" + str(i) + \"/\" + str(epochs)\n",
    "        pbar.set_description_str(description)\n",
    "\n",
    "        for X_batch, y_batch in dataset:\n",
    "\n",
    "            loss += train(X_batch, y_batch)\n",
    "            pbar.update(1)\n",
    "\n",
    "        loss /= len(dataset)\n",
    "        losses.append(loss.numpy())\n",
    "\n",
    "        training_sum = 0\n",
    "\n",
    "        print_statement = \"Loss :\" + str(loss.numpy()) + \" Evaluating Accuracy ...\"\n",
    "        pbar.set_postfix_str(print_statement)\n",
    "\n",
    "        for X_batch, y_batch in dataset:\n",
    "            training_sum += sum(predict(model, X_batch)==y_batch.numpy())\n",
    "        accuracy.append(training_sum/n_trainset)\n",
    "\n",
    "        print_statement = \"Loss :\" + str(loss.numpy()) + \" Accuracy :\" + str(accuracy[-1])\n",
    "\n",
    "        pbar.set_postfix_str(print_statement)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "test_sum = 0\n",
    "for X_batch, y_batch in testset:\n",
    "    test_sum += sum(predict(model, X_batch)==y_batch.numpy())\n",
    "print(test_sum/n_testset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.save(\"Models/capsnet_mnist.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"capsule_network_12\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"capsule_network_12\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ ConvolutionLayer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)       │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │        <span style=\"color: #00af00; text-decoration-color: #00af00\">20,992</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ BaseCapsule (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)        │     <span style=\"color: #00af00; text-decoration-color: #00af00\">5,308,672</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_36 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)              │        <span style=\"color: #00af00; text-decoration-color: #00af00\">82,432</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_37 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)             │       <span style=\"color: #00af00; text-decoration-color: #00af00\">525,312</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_38 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">784</span>)              │       <span style=\"color: #00af00; text-decoration-color: #00af00\">803,600</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ ConvolutionLayer (\u001b[38;5;33mConv2D\u001b[0m)       │ (\u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m256\u001b[0m)      │        \u001b[38;5;34m20,992\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ BaseCapsule (\u001b[38;5;33mConv2D\u001b[0m)            │ (\u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m256\u001b[0m)        │     \u001b[38;5;34m5,308,672\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_36 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m512\u001b[0m)              │        \u001b[38;5;34m82,432\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_37 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m1024\u001b[0m)             │       \u001b[38;5;34m525,312\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_38 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m784\u001b[0m)              │       \u001b[38;5;34m803,600\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">6,741,008</span> (25.71 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m6,741,008\u001b[0m (25.71 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">6,741,008</span> (25.71 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m6,741,008\u001b[0m (25.71 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 13 calls to <function CapsuleNetwork.regenerate_image at 0x0000016912D8A2A0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x300 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x300 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "n_samples = 5\n",
    "\n",
    "test_sample = X_test[:n_samples]\n",
    "# print(test_sample.shape)\n",
    "img_dims = test_sample.shape[1], test_sample.shape[2]\n",
    "features = model.predict_capsule_output(test_sample)\n",
    "\n",
    "temp_features = features.numpy()\n",
    "temp_ = temp_features.copy()\n",
    "\n",
    "plt.figure(figsize=(n_samples * 2, 3))\n",
    "for idx in range(n_samples):\n",
    "    pred = predict(model, tf.expand_dims(X_test[idx], axis=0))\n",
    "\n",
    "    temp_features[:,:,:,:] = 0\n",
    "    temp_features[idx:,:,idx,:] = temp_[idx:,:,idx,:]\n",
    "\n",
    "    reconstruction = model.regenerate_image(temp_features[idx])\n",
    "    reconstruction = tf.reshape(reconstruction, img_dims)\n",
    "\n",
    "    plt.subplot(1, n_samples, idx + 1)\n",
    "    plt.imshow(reconstruction, cmap=\"gray\")\n",
    "    plt.title(f\"Predicted: {pred}\")\n",
    "    plt.axis(\"off\")\n",
    "plt.show()   \n",
    "\n",
    "\n",
    "plt.figure(figsize=(n_samples * 2, 3))\n",
    "for idx in range(n_samples):\n",
    "    label = y_test[idx]\n",
    "    plt.subplot(1, n_samples, idx + 1)\n",
    "    plt.imshow(test_sample[idx], cmap=\"gray\")\n",
    "    plt.title(f\"Label: {label}\")\n",
    "    plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "# idx = 4\n",
    "\n",
    "# col = np.zeros((img_size, 308))\n",
    "# for i in range(16): \n",
    "#     feature_ = temp_features.copy()\n",
    "#     feature_[:,:,idx, i] += -0.25\n",
    "#     row = np.zeros((img_size, img_size))\n",
    "#     for j in range(10):\n",
    "#         feature_[:,:,idx, i] += 0.05\n",
    "#         feature_ = tf.convert_to_tensor(feature_)\n",
    "#         print(feature_.shape)\n",
    "#         row = np.hstack([\n",
    "#             row, \n",
    "#             tf.reshape(model.regenerate_image(feature_), \n",
    "#             (img_size, img_size)).numpy()\n",
    "#         ])\n",
    "#     col = np.vstack([col, row])\n",
    "    \n",
    "# plt.figure(figsize=(30,20))\n",
    "# plt.imshow(col[img_size:, img_size:], cmap='gray')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ds-ass2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST example Capsule Network model\n",
    "\n",
    "First, (re)constructed model is created for the well documented MNIST dataset in order to be able to compare with the foundational paper and other resources online attempting implementations of Capsule Networks.\n",
    "\n",
    "Once functionality for this is established it can be adapted to our Pneumonia task with the knowledge that the architecture functions should work properly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow.keras import Model, layers\n",
    "\n",
    "from ReadDataCG import train as trainc, test as testc, val as valc\n",
    "from ReadDataLocal import train as trainl, test as testl, val as vall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialisation and setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 12\n",
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "capsule_iterations = 2\n",
    "\n",
    "num_filters = 256\n",
    "num_base_mappings = 32\n",
    "dim_base_capsules = num_filters // num_base_mappings\n",
    "\n",
    "num_super_capsules = 10\n",
    "dim_super_capsules = 16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Util functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "def safe_normalise(vector, axis=1, epsilon=1e-7, keepdims=True):\n",
    "    norm_squared = tf.reduce_sum(tf.square(vector), axis, keepdims)\n",
    "    return tf.sqrt(norm_squared + epsilon)  # epsilon added to prevent division by 0\n",
    "\n",
    "def safe_squash(vector, axis=1, epsilon=1e-7):\n",
    "    norm_squared = tf.reduce_sum(\n",
    "        tf.square(vector), \n",
    "        axis=axis, \n",
    "        keepdims=True\n",
    "    )\n",
    "    scalar_factor = norm_squared / (1 + norm_squared)\n",
    "    \n",
    "    safe_normalise = tf.sqrt(norm_squared + epsilon)  # epsilon added to prevent division by 0\n",
    "    unit_vector = vector / safe_normalise\n",
    "    return scalar_factor * unit_vector\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_function(\n",
    "    vector, \n",
    "    reconstructed_image, \n",
    "    y, \n",
    "    y_image,\n",
    "    epsilon=1e-7,\n",
    "    m_plus=0.9,\n",
    "    m_minus=0.1,\n",
    "    lambda_=0.5,\n",
    "    alpha=0.0005,\n",
    "):\n",
    "    safe_normal = safe_normalise(vector, axis=-1, keepdims=True)\n",
    "    prediction = tf.reshape(safe_normal, [-1, num_super_capsules])\n",
    "\n",
    "    left_margin = tf.square(tf.maximum(0.0, m_plus - prediction))\n",
    "    right_margin = tf.square(tf.maximum(0.0, prediction - m_minus))\n",
    "\n",
    "    margin_loss = tf.add(y * left_margin, lambda_ * (1.0 - y) * right_margin)\n",
    "    margin_loss = tf.reduce_mean(tf.reduce_sum(margin_loss, axis=-1))\n",
    "\n",
    "    y_image_flat = tf.reshape(y_image, [-1, 784])  #!TODO HARDCODED 28x28 pixels\n",
    "    reconstruction_loss = tf.reduce_mean(tf.square(y_image_flat - reconstructed_image))\n",
    "\n",
    "    loss = tf.add(margin_loss, alpha * reconstruction_loss)\n",
    "\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_layer_output_imgsize(input_size: int, kernel_size: int = 9, strides: int = 1):\n",
    "    return (input_size - kernel_size) // strides"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading in the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MNIST toy data\n",
    "This is to build the model first with regular, well-documented matrix multiplication steps and reshapes.\n",
    "After this is completed, the model can be adapted to the Pneumonia dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([60000, 28, 28, 1]), TensorShape([10000, 28, 28, 1]))"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(X_train, y_train), (X_test , y_test) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "X_train = X_train / 255.0\n",
    "X_train = tf.cast(X_train, dtype=tf.float32)\n",
    "X_train = tf.expand_dims(X_train, axis=-1)\n",
    "\n",
    "X_test = X_test / 255.0\n",
    "X_test = tf.cast(X_test, dtype=tf.float32)\n",
    "X_test = tf.expand_dims(X_test, axis=-1)\n",
    "\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "cutoff = 256\n",
    "\n",
    "X_train, y_train = X_train[:cutoff], y_train[:cutoff]\n",
    "X_test, y_test = X_test[:cutoff], y_test[:cutoff]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Process and augment data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_trainset = X_train.shape[0]\n",
    "n_testset = X_test.shape[0]\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices((X_train, y_train))\n",
    "dataset = dataset.shuffle(buffer_size=len(dataset), reshuffle_each_iteration=True)\n",
    "dataset = dataset.batch(batch_size=batch_size)\n",
    "\n",
    "testset = tf.data.Dataset.from_tensor_slices((X_test, y_test))\n",
    "testset = testset.batch(batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Visually inspect data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x300 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(None, array([5, 0, 4, 1, 9], dtype=uint8))"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_samples = 5\n",
    "\n",
    "plt.figure(figsize=(n_samples * 2, 3))\n",
    "for index in range(n_samples):\n",
    "    plt.subplot(1, n_samples, index + 1)\n",
    "    sample_image = X_train[index]\n",
    "    plt.imshow(sample_image, cmap=\"binary\")\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "plt.show(), y_train[:n_samples]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the Capsule Network class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CapsuleNetwork(Model):\n",
    "    def __init__(\n",
    "        self, \n",
    "        num_filters, \n",
    "        num_base_mappings, dim_base_capsules, \n",
    "        num_super_capsules, dim_super_capsules, \n",
    "        iterations: int = 3,\n",
    "        kernel_size: int = 9):\n",
    "        super().__init__()\n",
    "        self.num_filters = num_filters\n",
    "        self.num_base_mappings = num_base_mappings\n",
    "        self.dim_base_capsules = dim_base_capsules\n",
    "        self.num_super_capsules = num_super_capsules\n",
    "        self.dim_super_capsules = dim_super_capsules\n",
    "        self.num_base_capsules = self.num_base_mappings * 6 ** 2\n",
    "\n",
    "        self.iterations = iterations\n",
    "        self.kernel_size = kernel_size\n",
    "\n",
    "        with tf.name_scope(\"Variables\") as scope:\n",
    "            kernel = [self.kernel_size, self.kernel_size]\n",
    "            \n",
    "            self.convolution = layers.Conv2D(self.num_filters, kernel, strides=[1,1], name='ConvolutionLayer', activation='relu')\n",
    "            self.base_capsule = layers.Conv2D(self.num_base_mappings * self.dim_base_capsules, kernel, strides=[2,2], name=\"BaseCapsule\")\n",
    "            self.w = tf.Variable(\n",
    "                tf.random_normal_initializer()(shape=[\n",
    "                    1, \n",
    "                    self.num_base_capsules, self.num_super_capsules, \n",
    "                    self.dim_super_capsules, self.dim_base_capsules\n",
    "                    ]), \n",
    "                dtype=tf.float32, \n",
    "                name=\"PoseEstimation\", \n",
    "                trainable=True)\n",
    "            \n",
    "            self.dense_1 = layers.Dense(units = 512, activation='relu')\n",
    "            self.dense_2 = layers.Dense(units = 1024, activation='relu')\n",
    "            self.dense_3 = layers.Dense(units = 784, activation='sigmoid', dtype='float32')\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        pass\n",
    "\n",
    "    def squash(self, vector, epsilon=1e-7):\n",
    "        with tf.name_scope(\"SafeSquashFunction\") as scope:\n",
    "            norm_squared = tf.reduce_sum(\n",
    "                tf.square(vector), \n",
    "                axis=-1, \n",
    "                keepdims=True\n",
    "            )\n",
    "            scalar_factor = norm_squared / (1 + norm_squared)\n",
    "            \n",
    "            safety_normalise = tf.sqrt(norm_squared + epsilon)\n",
    "            unit_vector = vector / safety_normalise\n",
    "            return scalar_factor * unit_vector\n",
    "\n",
    "    @tf.function\n",
    "    def call(self, inputs):\n",
    "        input_x, y = inputs\n",
    "        # input_x.shape: (None, 28, 28, 1)\n",
    "        # y.shape: (None, 10)\n",
    "\n",
    "        x = self.convolution(input_x) # x.shape: (None, 20, 20, 256)\n",
    "        x = self.base_capsule(x) # x.shape: (None, 6, 6, 256)\n",
    "\n",
    "        with tf.name_scope(\"CapsuleFormation\") as scope:\n",
    "            u = tf.reshape(x, (-1, self.num_base_mappings * x.shape[1] * x.shape[2], self.dim_base_capsules)) # u.shape: (None, 1152, 8)\n",
    "            u = tf.expand_dims(u, axis=-2) # u.shape: (None, 1152, 1, 8)\n",
    "            u = tf.expand_dims(u, axis=-1) # u.shape: (None, 1152, 1, 8, 1)\n",
    "            u_hat = tf.matmul(self.w, u) # u_hat.shape: (None, 1152, 10, 16, 1)\n",
    "            u_hat = tf.squeeze(u_hat, [4]) # u_hat.shape: (None, 1152, 10, 16)\n",
    "\n",
    "\n",
    "        with tf.name_scope(\"DynamicRouting\") as scope:\n",
    "            b = tf.zeros((input_x.shape[0], 1152, self.num_super_capsules, 1)) # b.shape: (None, 1152, 10, 1)\n",
    "            for i in range(self.iterations): # self.iterations = 3\n",
    "                c = tf.nn.softmax(b, axis=-2) # c.shape: (None, 1152, 10, 1)\n",
    "                s = tf.reduce_sum(tf.multiply(c, u_hat), axis=1, keepdims=True) # s.shape: (None, 1, 10, 16)\n",
    "                v = self.squash(s) # v.shape: (None, 1, 10, 16)\n",
    "                agreement = tf.squeeze(tf.matmul(tf.expand_dims(u_hat, axis=-1), tf.expand_dims(v, axis=-1), transpose_a=True), [4]) # agreement.shape: (None, 1152, 10, 1)\n",
    "                # Before matmul following intermediate shapes are present, they are not assigned to a variable but just for understanding the code.\n",
    "                # u_hat.shape (Intermediate shape) : (None, 1152, 10, 16, 1)\n",
    "                # v.shape (Intermediate shape): (None, 1, 10, 16, 1)\n",
    "                # Since the first parameter of matmul is to be transposed its shape becomes:(None, 1152, 10, 1, 16)\n",
    "                # Now matmul is performed in the last two dimensions, and others are broadcasted\n",
    "                # Before squeezing we have an intermediate shape of (None, 1152, 10, 1, 1)\n",
    "                b += agreement\n",
    "\n",
    "        with tf.name_scope(\"Masking\") as scope:\n",
    "            y = tf.expand_dims(y, axis=-1) # y.shape: (None, 10, 1)\n",
    "            y = tf.expand_dims(y, axis=1) # y.shape: (None, 1, 10, 1)\n",
    "            mask = tf.cast(y, dtype=tf.float32) # mask.shape: (None, 1, 10, 1)\n",
    "            v_masked = tf.multiply(mask, v) # v_masked.shape: (None, 1, 10, 16)\n",
    "\n",
    "        with tf.name_scope(\"Reconstruction\") as scope:\n",
    "            v_ = tf.reshape(v_masked, [-1, self.num_super_capsules * self.dim_super_capsules]) # v_.shape: (None, 160)\n",
    "            reconstructed_image = self.dense_1(v_) # reconstructed_image.shape: (None, 512)\n",
    "            reconstructed_image = self.dense_2(reconstructed_image) # reconstructed_image.shape: (None, 1024)\n",
    "            reconstructed_image = self.dense_3(reconstructed_image) # reconstructed_image.shape: (None, 784)\n",
    "\n",
    "        return v, reconstructed_image\n",
    "\n",
    "    @tf.function\n",
    "    def predict_capsule_output(self, inputs):\n",
    "        x = self.convolution(inputs) # x.shape: (None, 20, 20, 256)\n",
    "        x = self.base_capsule(x) # x.shape: (None, 6, 6, 256)\n",
    "\n",
    "        with tf.name_scope(\"CapsuleFormation\") as scope:\n",
    "            u = tf.reshape(x, (-1, self.num_base_capsules, self.dim_base_capsules)) # u.shape: (None, 1152, 8)\n",
    "            u = tf.expand_dims(u, axis=-2) # u.shape: (None, 1152, 1, 8)\n",
    "            u = tf.expand_dims(u, axis=-1) # u.shape: (None, 1152, 1, 8, 1)\n",
    "            u_hat = tf.matmul(self.w, u) # u_hat.shape: (None, 1152, 10, 16, 1)\n",
    "            u_hat = tf.squeeze(u_hat, [4]) # u_hat.shape: (None, 1152, 10, 16)\n",
    "\n",
    "\n",
    "        with tf.name_scope(\"DynamicRouting\") as scope:\n",
    "            b = tf.zeros((inputs.shape[0], 1152, self.num_super_capsules, 1)) # b.shape: (None, 1152, 10, 1)\n",
    "            for i in range(self.iterations): # self.iterations = 3\n",
    "                c = tf.nn.softmax(b, axis=-2) # c.shape: (None, 1152, 10, 1)\n",
    "                s = tf.reduce_sum(tf.multiply(c, u_hat), axis=1, keepdims=True) # s.shape: (None, 1, 10, 16)\n",
    "                v = self.squash(s) # v.shape: (None, 1, 10, 16)\n",
    "                agreement = tf.squeeze(tf.matmul(tf.expand_dims(u_hat, axis=-1), tf.expand_dims(v, axis=-1), transpose_a=True), [4]) # agreement.shape: (None, 1152, 10, 1)\n",
    "                # Before matmul following intermediate shapes are present, they are not assigned to a variable but just for understanding the code.\n",
    "                # u_hat.shape (Intermediate shape) : (None, 1152, 10, 16, 1)\n",
    "                # v.shape (Intermediate shape): (None, 1, 10, 16, 1)\n",
    "                # Since the first parameter of matmul is to be transposed its shape becomes:(None, 1152, 10, 1, 16)\n",
    "                # Now matmul is performed in the last two dimensions, and others are broadcasted\n",
    "                # Before squeezing we have an intermediate shape of (None, 1152, 10, 1, 1)\n",
    "                b += agreement\n",
    "        return v\n",
    "\n",
    "    @tf.function\n",
    "    def regenerate_image(self, inputs):\n",
    "        with tf.name_scope(\"Reconstruction\") as scope:\n",
    "            v_ = tf.reshape(inputs, [-1, self.num_super_capsules * self.dim_super_capsules]) # v_.shape: (None, 160)\n",
    "            reconstructed_image = self.dense_1(v_) # reconstructed_image.shape: (None, 512)\n",
    "            reconstructed_image = self.dense_2(reconstructed_image) # reconstructed_image.shape: (None, 1024)\n",
    "            reconstructed_image = self.dense_3(reconstructed_image) # reconstructed_image.shape: (None, 784)\n",
    "        return reconstructed_image\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instantiate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No `profiler_outdir` passed to trace_on(). Profiler won't be enabled.\n"
     ]
    }
   ],
   "source": [
    "tf.summary.trace_on(graph=True, profiler=True)\n",
    "model = CapsuleNetwork(\n",
    "    num_filters=num_filters,\n",
    "    num_base_mappings=num_base_mappings,\n",
    "    dim_base_capsules=dim_base_capsules,\n",
    "    num_super_capsules=num_super_capsules,\n",
    "    dim_super_capsules=dim_super_capsules,\n",
    "    iterations=capsule_iterations\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "Optimiser = tf.keras.optimizers.Adam()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Error while stopping profiler: Cannot export profiling results. No profiler is running.\n"
     ]
    }
   ],
   "source": [
    "def train(x,y):\n",
    "    y_one_hot = tf.one_hot(y, depth=num_super_capsules)\n",
    "    with tf.GradientTape() as tape:\n",
    "        v, reconstructed_image = model([x, y_one_hot])\n",
    "        loss = loss_function(v, reconstructed_image, y_one_hot, x)\n",
    "    grad = tape.gradient(loss, model.trainable_variables)\n",
    "    Optimiser.apply_gradients(zip(grad, model.trainable_variables))\n",
    "    return loss\n",
    "\n",
    "# _ = train(X_train[:32], y_train[:32])\n",
    "\n",
    "tf.summary.trace_off()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, x):\n",
    "    pred = model.predict_capsule_output(x)\n",
    "    pred_normed = safe_normalise(pred)\n",
    "    pred_normed = tf.squeeze(pred_normed, [1])\n",
    "    return np.argmax(pred_normed, axis=1)[:,0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/12: 100%|██████████| 4/4 [00:25<00:00,  6.44s/it, Loss :0.79423 Accuracy :0.109375]     \n",
      "Epoch 2/12: 100%|██████████| 4/4 [00:23<00:00,  5.87s/it, Loss :0.47385117 Accuracy :0.421875]     \n",
      "Epoch 3/12: 100%|██████████| 4/4 [00:23<00:00,  5.81s/it, Loss :0.36695212 Accuracy :0.5703125]    \n",
      "Epoch 4/12: 100%|██████████| 4/4 [00:23<00:00,  5.87s/it, Loss :0.27144134 Accuracy :0.625]        \n",
      "Epoch 5/12: 100%|██████████| 4/4 [00:23<00:00,  5.78s/it, Loss :0.1847026 Accuracy :0.65625]      \n",
      "Epoch 6/12: 100%|██████████| 4/4 [00:23<00:00,  5.95s/it, Loss :0.1337586 Accuracy :0.703125]     \n",
      "Epoch 7/12: 100%|██████████| 4/4 [00:23<00:00,  5.76s/it, Loss :0.10265607 Accuracy :0.7421875]    \n",
      "Epoch 8/12: 100%|██████████| 4/4 [00:23<00:00,  5.76s/it, Loss :0.078339465 Accuracy :0.79296875]   \n",
      "Epoch 9/12: 100%|██████████| 4/4 [00:23<00:00,  5.97s/it, Loss :0.062224172 Accuracy :0.8203125]    \n",
      "Epoch 10/12: 100%|██████████| 4/4 [00:23<00:00,  5.85s/it, Loss :0.049095843 Accuracy :0.8125]       \n",
      "Epoch 11/12: 100%|██████████| 4/4 [00:24<00:00,  6.05s/it, Loss :0.038500518 Accuracy :0.84765625]   \n",
      "Epoch 12/12: 100%|██████████| 4/4 [00:24<00:00,  6.02s/it, Loss :0.030238086 Accuracy :0.85546875]   \n"
     ]
    }
   ],
   "source": [
    "checkpoint = tf.train.Checkpoint(model=model)\n",
    "losses = []\n",
    "accuracy = []\n",
    "for i in range(1, epochs+1, 1):\n",
    "\n",
    "    loss = 0\n",
    "    with tqdm(total=len(dataset)) as pbar:\n",
    "\n",
    "        description = \"Epoch \" + str(i) + \"/\" + str(epochs)\n",
    "        pbar.set_description_str(description)\n",
    "\n",
    "        for X_batch, y_batch in dataset:\n",
    "\n",
    "            loss += train(X_batch,y_batch)\n",
    "            pbar.update(1)\n",
    "\n",
    "        loss /= len(dataset)\n",
    "        losses.append(loss.numpy())\n",
    "\n",
    "        training_sum = 0\n",
    "\n",
    "        print_statement = \"Loss :\" + str(loss.numpy()) + \" Evaluating Accuracy ...\"\n",
    "        pbar.set_postfix_str(print_statement)\n",
    "\n",
    "        for X_batch, y_batch in dataset:\n",
    "            training_sum += sum(predict(model, X_batch)==y_batch.numpy())\n",
    "        accuracy.append(training_sum/n_trainset)\n",
    "\n",
    "        print_statement = \"Loss :\" + str(loss.numpy()) + \" Accuracy :\" + str(accuracy[-1])\n",
    "\n",
    "        pbar.set_postfix_str(print_statement)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.61328125\n"
     ]
    }
   ],
   "source": [
    "test_sum = 0\n",
    "for X_batch, y_batch in testset:\n",
    "    test_sum += sum(predict(model, X_batch)==y_batch.numpy())\n",
    "print(test_sum/n_testset)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ass2-R-GjqHgr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

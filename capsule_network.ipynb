{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST example Capsule Network model\n",
    "\n",
    "First, (re)constructed model is created for the well documented MNIST dataset in order to be able to compare with the foundational paper and other resources online attempting implementations of Capsule Networks.\n",
    "\n",
    "Once functionality for this is established it can be adapted to our Pneumonia task with the knowledge that the architecture functions should work properly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# from ReadDataCG import train as trainc, test as testc, val as valc\n",
    "# from ReadDataLocal import train as trainl, test as testl, val as vall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialisation and setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cutoff = 2048\n",
    "\n",
    "epochs = 6\n",
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "capsule_iterations = 2\n",
    "\n",
    "num_filters = 256\n",
    "num_base_mappings = 32\n",
    "dim_base_capsules = num_filters // num_base_mappings\n",
    "\n",
    "num_super_capsules = 10\n",
    "dim_super_capsules = 16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Util functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def safe_normalise(vector, axis=1, epsilon=1e-7, keepdims=True):\n",
    "    norm_squared = tf.reduce_sum(tf.square(vector), axis, keepdims)\n",
    "    return tf.sqrt(norm_squared + epsilon)  # epsilon added to prevent division by 0\n",
    "\n",
    "def safe_squash(vector, axis=1, epsilon=1e-7):\n",
    "    norm_squared = tf.reduce_sum(\n",
    "        tf.square(vector), \n",
    "        axis=axis, \n",
    "        keepdims=True\n",
    "    )\n",
    "    scalar_factor = norm_squared / (1 + norm_squared)\n",
    "    \n",
    "    safe_normalise = tf.sqrt(norm_squared + epsilon)  # epsilon added to prevent division by 0\n",
    "    unit_vector = vector / safe_normalise\n",
    "    return scalar_factor * unit_vector\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_function(\n",
    "    vector, \n",
    "    reconstructed_image, \n",
    "    y, \n",
    "    y_image,\n",
    "    epsilon=1e-7,\n",
    "    m_plus=0.9,\n",
    "    m_minus=0.1,\n",
    "    lambda_=0.5,\n",
    "    alpha=0.0005,\n",
    "):\n",
    "    safe_normal = safe_normalise(vector, axis=-1, keepdims=True)\n",
    "    prediction = tf.reshape(safe_normal, [-1, num_super_capsules])\n",
    "\n",
    "    left_margin = tf.square(tf.maximum(0.0, m_plus - prediction))\n",
    "    right_margin = tf.square(tf.maximum(0.0, prediction - m_minus))\n",
    "\n",
    "    margin_loss = tf.add(y * left_margin, lambda_ * (1.0 - y) * right_margin)\n",
    "    margin_loss = tf.reduce_mean(tf.reduce_sum(margin_loss, axis=-1))\n",
    "\n",
    "    y_image_flat = tf.reshape(y_image, [-1, 784])  #!TODO HARDCODED 28x28 pixels\n",
    "    reconstruction_loss = tf.reduce_mean(tf.square(y_image_flat - reconstructed_image))\n",
    "\n",
    "    loss = tf.add(margin_loss, alpha * reconstruction_loss)\n",
    "\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_layer_output_imgsize(input_size: int, kernel_size: int = 9, strides: int = 1):\n",
    "    return (input_size - kernel_size) // strides"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading in the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MNIST toy data\n",
    "This is to build the model first with regular, well-documented matrix multiplication steps and reshapes.\n",
    "After this is completed, the model can be adapted to the Pneumonia dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([60000, 28, 28, 1]), TensorShape([10000, 28, 28, 1]))"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(X_train, y_train), (X_test , y_test) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "X_train = X_train / 255.0\n",
    "X_train = tf.cast(X_train, dtype=tf.float32)\n",
    "X_train = tf.expand_dims(X_train, axis=-1)\n",
    "\n",
    "X_test = X_test / 255.0\n",
    "X_test = tf.cast(X_test, dtype=tf.float32)\n",
    "X_test = tf.expand_dims(X_test, axis=-1)\n",
    "\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use a smaller set for development and testing\n",
    "if cutoff > 0:\n",
    "    try:\n",
    "        X_train, y_train = X_train[:cutoff], y_train[:cutoff]\n",
    "    except Exception as e:\n",
    "        pass\n",
    "    try:\n",
    "        X_test, y_test = X_test[:cutoff], y_test[:cutoff]\n",
    "    except Exception as e:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Process and augment data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_trainset = X_train.shape[0]\n",
    "n_testset = X_test.shape[0]\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices((X_train, y_train))\n",
    "dataset = dataset.shuffle(buffer_size=len(dataset), reshuffle_each_iteration=True)\n",
    "dataset = dataset.batch(batch_size=batch_size)\n",
    "\n",
    "testset = tf.data.Dataset.from_tensor_slices((X_test, y_test))\n",
    "testset = testset.batch(batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Visually inspect data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x300 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(None, array([5, 0, 4, 1, 9], dtype=uint8))"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_samples = 5\n",
    "\n",
    "plt.figure(figsize=(n_samples * 2, 3))\n",
    "for index in range(n_samples):\n",
    "    plt.subplot(1, n_samples, index + 1)\n",
    "    sample_image = X_train[index]\n",
    "    plt.imshow(sample_image, cmap=\"binary\")\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "plt.show(), y_train[:n_samples]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the Capsule Network class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CapsuleNetwork(tf.keras.Model):\n",
    "    def __init__(\n",
    "        self, \n",
    "        num_filters, \n",
    "        num_base_mappings, dim_base_capsules, \n",
    "        num_super_capsules, dim_super_capsules, \n",
    "        iterations: int = 3,\n",
    "        kernel_size: int = 9):\n",
    "        super().__init__()\n",
    "        self.num_filters = num_filters\n",
    "        self.num_base_mappings = num_base_mappings\n",
    "        self.dim_base_capsules = dim_base_capsules\n",
    "        self.num_super_capsules = num_super_capsules\n",
    "        self.dim_super_capsules = dim_super_capsules\n",
    "        self.num_base_capsules = self.num_base_mappings * 6 ** 2\n",
    "\n",
    "        self.iterations = iterations\n",
    "        self.kernel_size = kernel_size\n",
    "\n",
    "        with tf.name_scope(\"Variables\") as scope:\n",
    "            kernel = [self.kernel_size, self.kernel_size]\n",
    "            \n",
    "            self.convolution = tf.keras.layers.Conv2D(self.num_filters, kernel, strides=[1,1], name='ConvolutionLayer', activation='relu')\n",
    "            self.base_capsule = tf.keras.layers.Conv2D(self.num_base_mappings * self.dim_base_capsules, kernel, strides=[2,2], name=\"BaseCapsule\")\n",
    "            self.w = tf.Variable(\n",
    "                tf.random_normal_initializer()(shape=[\n",
    "                    1, \n",
    "                    self.num_base_capsules, self.num_super_capsules, \n",
    "                    self.dim_super_capsules, self.dim_base_capsules\n",
    "                    ]), \n",
    "                dtype=tf.float32, \n",
    "                name=\"PoseEstimation\", \n",
    "                trainable=True)\n",
    "            \n",
    "            self.dense_1 = tf.keras.layers.Dense(units = 512, activation='relu')\n",
    "            self.dense_2 = tf.keras.layers.Dense(units = 1024, activation='relu')\n",
    "            self.dense_3 = tf.keras.layers.Dense(units = 784, activation='sigmoid', dtype='float32')\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        pass\n",
    "\n",
    "    def squash(self, vector, epsilon=1e-7):\n",
    "        with tf.name_scope(\"SafeSquashFunction\") as scope:\n",
    "            norm_squared = tf.reduce_sum(\n",
    "                tf.square(vector), \n",
    "                axis=-1, \n",
    "                keepdims=True\n",
    "            )\n",
    "            scalar_factor = norm_squared / (1 + norm_squared)\n",
    "            \n",
    "            safety_normalise = tf.sqrt(norm_squared + epsilon)\n",
    "            unit_vector = vector / safety_normalise\n",
    "            return scalar_factor * unit_vector\n",
    "\n",
    "    @tf.function\n",
    "    def call(self, inputs):\n",
    "        input_x, y = inputs\n",
    "        # input_x.shape: (None, 28, 28, 1)\n",
    "        # y.shape: (None, 10)\n",
    "\n",
    "        x = self.convolution(input_x) # x.shape: (None, 20, 20, 256)\n",
    "        x = self.base_capsule(x) # x.shape: (None, 6, 6, 256)\n",
    "\n",
    "        with tf.name_scope(\"CapsuleFormation\") as scope:\n",
    "            u = tf.reshape(x, (-1, self.num_base_mappings * x.shape[1] * x.shape[2], self.dim_base_capsules)) # u.shape: (None, 1152, 8)\n",
    "            u = tf.expand_dims(u, axis=-2) # u.shape: (None, 1152, 1, 8)\n",
    "            u = tf.expand_dims(u, axis=-1) # u.shape: (None, 1152, 1, 8, 1)\n",
    "            u_hat = tf.matmul(self.w, u) # u_hat.shape: (None, 1152, 10, 16, 1)\n",
    "            u_hat = tf.squeeze(u_hat, [4]) # u_hat.shape: (None, 1152, 10, 16)\n",
    "\n",
    "\n",
    "        with tf.name_scope(\"DynamicRouting\") as scope:\n",
    "            b = tf.zeros((input_x.shape[0], 1152, self.num_super_capsules, 1)) # b.shape: (None, 1152, 10, 1)\n",
    "            for i in range(self.iterations): # self.iterations = 3\n",
    "                c = tf.nn.softmax(b, axis=-2) # c.shape: (None, 1152, 10, 1)\n",
    "                s = tf.reduce_sum(tf.multiply(c, u_hat), axis=1, keepdims=True) # s.shape: (None, 1, 10, 16)\n",
    "                v = self.squash(s) # v.shape: (None, 1, 10, 16)\n",
    "                agreement = tf.squeeze(tf.matmul(tf.expand_dims(u_hat, axis=-1), tf.expand_dims(v, axis=-1), transpose_a=True), [4]) # agreement.shape: (None, 1152, 10, 1)\n",
    "                # Before matmul following intermediate shapes are present, they are not assigned to a variable but just for understanding the code.\n",
    "                # u_hat.shape (Intermediate shape) : (None, 1152, 10, 16, 1)\n",
    "                # v.shape (Intermediate shape): (None, 1, 10, 16, 1)\n",
    "                # Since the first parameter of matmul is to be transposed its shape becomes:(None, 1152, 10, 1, 16)\n",
    "                # Now matmul is performed in the last two dimensions, and others are broadcasted\n",
    "                # Before squeezing we have an intermediate shape of (None, 1152, 10, 1, 1)\n",
    "                b += agreement\n",
    "\n",
    "        with tf.name_scope(\"Masking\") as scope:\n",
    "            y = tf.expand_dims(y, axis=-1) # y.shape: (None, 10, 1)\n",
    "            y = tf.expand_dims(y, axis=1) # y.shape: (None, 1, 10, 1)\n",
    "            mask = tf.cast(y, dtype=tf.float32) # mask.shape: (None, 1, 10, 1)\n",
    "            v_masked = tf.multiply(mask, v) # v_masked.shape: (None, 1, 10, 16)\n",
    "\n",
    "        with tf.name_scope(\"Reconstruction\") as scope:\n",
    "            v_ = tf.reshape(v_masked, [-1, self.num_super_capsules * self.dim_super_capsules]) # v_.shape: (None, 160)\n",
    "            reconstructed_image = self.dense_1(v_) # reconstructed_image.shape: (None, 512)\n",
    "            reconstructed_image = self.dense_2(reconstructed_image) # reconstructed_image.shape: (None, 1024)\n",
    "            reconstructed_image = self.dense_3(reconstructed_image) # reconstructed_image.shape: (None, 784)\n",
    "\n",
    "        return v, reconstructed_image\n",
    "\n",
    "    @tf.function\n",
    "    def predict_capsule_output(self, inputs):\n",
    "        x = self.convolution(inputs) # x.shape: (None, 20, 20, 256)\n",
    "        x = self.base_capsule(x) # x.shape: (None, 6, 6, 256)\n",
    "\n",
    "        with tf.name_scope(\"CapsuleFormation\") as scope:\n",
    "            u = tf.reshape(x, (-1, self.num_base_capsules, self.dim_base_capsules)) # u.shape: (None, 1152, 8)\n",
    "            u = tf.expand_dims(u, axis=-2) # u.shape: (None, 1152, 1, 8)\n",
    "            u = tf.expand_dims(u, axis=-1) # u.shape: (None, 1152, 1, 8, 1)\n",
    "            u_hat = tf.matmul(self.w, u) # u_hat.shape: (None, 1152, 10, 16, 1)\n",
    "            u_hat = tf.squeeze(u_hat, [4]) # u_hat.shape: (None, 1152, 10, 16)\n",
    "\n",
    "\n",
    "        with tf.name_scope(\"DynamicRouting\") as scope:\n",
    "            b = tf.zeros((inputs.shape[0], 1152, self.num_super_capsules, 1)) # b.shape: (None, 1152, 10, 1)\n",
    "            for i in range(self.iterations): # self.iterations = 3\n",
    "                c = tf.nn.softmax(b, axis=-2) # c.shape: (None, 1152, 10, 1)\n",
    "                s = tf.reduce_sum(tf.multiply(c, u_hat), axis=1, keepdims=True) # s.shape: (None, 1, 10, 16)\n",
    "                v = self.squash(s) # v.shape: (None, 1, 10, 16)\n",
    "                agreement = tf.squeeze(tf.matmul(tf.expand_dims(u_hat, axis=-1), tf.expand_dims(v, axis=-1), transpose_a=True), [4]) # agreement.shape: (None, 1152, 10, 1)\n",
    "                # Before matmul following intermediate shapes are present, they are not assigned to a variable but just for understanding the code.\n",
    "                # u_hat.shape (Intermediate shape) : (None, 1152, 10, 16, 1)\n",
    "                # v.shape (Intermediate shape): (None, 1, 10, 16, 1)\n",
    "                # Since the first parameter of matmul is to be transposed its shape becomes:(None, 1152, 10, 1, 16)\n",
    "                # Now matmul is performed in the last two dimensions, and others are broadcasted\n",
    "                # Before squeezing we have an intermediate shape of (None, 1152, 10, 1, 1)\n",
    "                b += agreement\n",
    "        return v\n",
    "\n",
    "    @tf.function\n",
    "    def regenerate_image(self, inputs):\n",
    "        with tf.name_scope(\"Reconstruction\") as scope:\n",
    "            v_ = tf.reshape(inputs, [-1, self.num_super_capsules * self.dim_super_capsules]) # v_.shape: (None, 160)\n",
    "            reconstructed_image = self.dense_1(v_) # reconstructed_image.shape: (None, 512)\n",
    "            reconstructed_image = self.dense_2(reconstructed_image) # reconstructed_image.shape: (None, 1024)\n",
    "            reconstructed_image = self.dense_3(reconstructed_image) # reconstructed_image.shape: (None, 784)\n",
    "        return reconstructed_image\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instantiate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No `profiler_outdir` passed to trace_on(). Profiler won't be enabled.\n"
     ]
    }
   ],
   "source": [
    "tf.summary.trace_on(graph=True, profiler=True)\n",
    "model = CapsuleNetwork(\n",
    "    num_filters=num_filters,\n",
    "    num_base_mappings=num_base_mappings,\n",
    "    dim_base_capsules=dim_base_capsules,\n",
    "    num_super_capsules=num_super_capsules,\n",
    "    dim_super_capsules=dim_super_capsules,\n",
    "    iterations=capsule_iterations\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "Optimiser = tf.keras.optimizers.Adam()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Error while stopping profiler: Cannot export profiling results. No profiler is running.\n"
     ]
    }
   ],
   "source": [
    "def train(x,y):\n",
    "    y_one_hot = tf.one_hot(y, depth=num_super_capsules)\n",
    "    with tf.GradientTape() as tape:\n",
    "        v, reconstructed_image = model([x, y_one_hot])\n",
    "        loss = loss_function(v, reconstructed_image, y_one_hot, x)\n",
    "    grad = tape.gradient(loss, model.trainable_variables)\n",
    "    Optimiser.apply_gradients(zip(grad, model.trainable_variables))\n",
    "    return loss\n",
    "\n",
    "# _ = train(X_train[:32], y_train[:32])\n",
    "\n",
    "tf.summary.trace_off()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, x):\n",
    "    pred = model.predict_capsule_output(x)\n",
    "    pred_normed = safe_normalise(pred)\n",
    "    pred_normed = tf.squeeze(pred_normed, [1])\n",
    "    return np.argmax(pred_normed, axis=1)[:,0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/6:   0%|          | 0/938 [00:00<?, ?it/s]W0000 00:00:1744877637.403584  124224 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1744877637.404555  124224 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1744877637.405528  124224 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1744877637.406496  124224 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1744877637.407471  124224 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1744877637.408428  124224 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1744877637.409402  124224 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1744877637.412221  124224 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1744877637.414515  124224 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1744877637.417556  124224 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1744877637.420208  124224 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1744877637.423645  124224 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1744877637.427106  124224 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1744877637.434326  124224 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1744877637.436419  124224 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1744877637.446239  124224 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1744877637.449623  124224 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1744877637.452450  124224 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1744877637.455499  124224 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1744877637.459126  124224 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1744877637.462329  124224 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1744877637.466556  124224 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1744877637.469859  124224 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1744877637.473438  124224 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1744877637.476658  124224 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1744877637.481027  124224 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1744877637.487307  124224 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1744877637.492432  124224 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1744877637.498588  124224 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1744877637.505761  124224 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1744877637.518059  124224 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1744877637.833356  124222 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1744877637.839971  124222 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1744877637.843141  124222 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1744877637.845848  124222 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1744877637.849527  124222 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1744877637.853258  124222 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1744877637.856369  124222 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1744877637.859975  124222 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1744877637.863366  124222 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1744877637.867685  124222 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1744877637.871509  124222 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1744877637.875412  124222 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1744877637.879081  124222 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1744877637.883798  124222 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1744877637.894002  124222 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1744877637.905401  124222 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1744877637.917054  124222 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1744877637.923437  124222 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1744877637.937739  124222 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1744877637.945121  124222 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1744877637.950223  124222 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1744877637.957643  124222 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1744877637.965989  124222 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1744877637.972368  124222 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1744877637.979237  124222 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1744877637.987019  124222 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1744877637.996370  124222 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1744877638.005993  124222 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1744877638.026553  124222 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1744877638.034008  124222 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1744877638.053307  124222 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1744877638.060022  124222 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1744877638.063745  124222 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1744877638.064963  124222 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1744877638.076258  124222 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1744877638.088035  124222 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1744877638.099404  124222 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1744877638.118809  124222 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1744877638.132400  124222 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1744877638.152499  124222 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1744877638.171225  124222 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1744877638.181152  124222 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1744877638.195695  124222 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1744877638.197122  124222 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1744877638.203753  124222 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1744877638.207181  124222 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1744877638.211120  124222 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1744877638.212248  124222 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1744877638.213871  124222 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1744877638.214905  124222 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1744877638.216224  124222 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1744877638.217279  124222 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1744877638.218587  124222 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1744877638.219540  124222 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1744877638.221105  124222 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1744877638.222359  124222 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1744877638.223635  124222 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1744877638.224606  124222 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1744877638.225591  124222 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1744877638.226869  124222 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1744877638.227777  124222 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1744877638.228688  124222 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1744877638.230249  124222 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1744877638.232197  124222 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1744877638.233869  124222 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1744877638.234894  124222 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1744877638.237156  124222 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1744877638.240982  124222 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "Epoch 1/6: 100%|██████████| 938/938 [06:05<00:00,  2.57it/s, Loss :0.04849994 Accuracy :0.7604166666666666]\n",
      "Epoch 2/6: 100%|██████████| 938/938 [05:55<00:00,  2.64it/s, Loss :0.019662995 Accuracy :0.78305]      \n",
      "Epoch 3/6: 100%|██████████| 938/938 [06:03<00:00,  2.58it/s, Loss :0.014582344 Accuracy :0.7837]       \n",
      "Epoch 4/6: 100%|██████████| 938/938 [04:45<00:00,  3.68it/s]2025-04-17 10:36:47.087592: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "Epoch 4/6: 100%|██████████| 938/938 [06:10<00:00,  2.53it/s, Loss :0.011488571 Accuracy :0.8069666666666667]\n",
      "Epoch 5/6: 100%|██████████| 938/938 [06:28<00:00,  2.41it/s, Loss :0.009397166 Accuracy :0.8147666666666666]\n",
      "Epoch 6/6:  55%|█████▌    | 516/938 [02:30<02:10,  3.23it/s]"
     ]
    }
   ],
   "source": [
    "checkpoint = tf.train.Checkpoint(model=model)\n",
    "losses = []\n",
    "accuracy = []\n",
    "for i in range(1, epochs+1, 1):\n",
    "\n",
    "    loss = 0\n",
    "    with tqdm(total=len(dataset)) as pbar:\n",
    "\n",
    "        description = \"Epoch \" + str(i) + \"/\" + str(epochs)\n",
    "        pbar.set_description_str(description)\n",
    "\n",
    "        for X_batch, y_batch in dataset:\n",
    "\n",
    "            loss += train(X_batch,y_batch)\n",
    "            pbar.update(1)\n",
    "\n",
    "        loss /= len(dataset)\n",
    "        losses.append(loss.numpy())\n",
    "\n",
    "        training_sum = 0\n",
    "\n",
    "        print_statement = \"Loss :\" + str(loss.numpy()) + \" Evaluating Accuracy ...\"\n",
    "        pbar.set_postfix_str(print_statement)\n",
    "\n",
    "        for X_batch, y_batch in dataset:\n",
    "            training_sum += sum(predict(model, X_batch)==y_batch.numpy())\n",
    "        accuracy.append(training_sum/n_trainset)\n",
    "\n",
    "        print_statement = \"Loss :\" + str(loss.numpy()) + \" Accuracy :\" + str(accuracy[-1])\n",
    "\n",
    "        pbar.set_postfix_str(print_statement)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.578125\n"
     ]
    }
   ],
   "source": [
    "test_sum = 0\n",
    "for X_batch, y_batch in testset:\n",
    "    test_sum += sum(predict(model, X_batch)==y_batch.numpy())\n",
    "print(test_sum/n_testset)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ds-ass2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
